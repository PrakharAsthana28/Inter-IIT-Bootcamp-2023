{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-12T09:25:01.735784Z",
     "start_time": "2024-10-12T09:25:00.953190Z"
    }
   },
   "source": [
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the dataset class\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_files, label_folder, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.label_folder = label_folder\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        label_path = os.path.join(self.label_folder, os.path.basename(img_path).replace('.jpg', '_label.png'))\n",
    "        label = Image.open(label_path).convert('L')  # Convert to grayscale\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            label = self.transform(label)\n",
    "        \n",
    "        return img, torch.tensor(np.array(label), dtype=torch.long)\n",
    "\n",
    "# Data transformation\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create dataset\n",
    "image_folder = 'D:/New folder/Inter_Bootcamp/dataset/train'  # Update with your image folder path\n",
    "label_folder = 'D:/New folder/Inter_Bootcamp/dataset/labels'  # Update with your label folder path\n",
    "image_files = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith('.jpg')]\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "train_files, val_files = train_test_split(image_files, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create DataLoader for training and validation\n",
    "train_dataset = SegmentationDataset(train_files, label_folder, transform=data_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "val_dataset = SegmentationDataset(val_files, label_folder, transform=data_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Load pre-trained model from SMP\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",        # Choose any encoder available in SMP\n",
    "    encoder_weights=\"imagenet\",     # Use pre-trained weights\n",
    "    classes=3,                      # Number of segmentation classes\n",
    "    activation=None                 # Raw logits\n",
    ")\n",
    "\n",
    "# Move model to GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss and metrics\n",
    "loss_fn = smp.losses.DiceLoss(mode='multiclass')\n",
    "metrics = [\n",
    "    smp.utils.metrics.IoU(threshold=0.5),  # Intersection over Union\n",
    "    smp.utils.metrics.Fscore(beta=1.0)     # F-Beta Score\n",
    "]\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 25\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        imgs, labels = batch\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            imgs, labels = batch\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            val_loss += loss_fn(outputs, labels).item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}, Val Loss: {val_loss/len(val_loader):.4f}\")"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 44\u001B[0m\n\u001B[0;32m     41\u001B[0m image_files \u001B[38;5;241m=\u001B[39m [os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(image_folder, f) \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m os\u001B[38;5;241m.\u001B[39mlistdir(image_folder) \u001B[38;5;28;01mif\u001B[39;00m f\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.jpg\u001B[39m\u001B[38;5;124m'\u001B[39m)]\n\u001B[0;32m     43\u001B[0m \u001B[38;5;66;03m# Split dataset into training and validation sets\u001B[39;00m\n\u001B[1;32m---> 44\u001B[0m train_files, val_files \u001B[38;5;241m=\u001B[39m train_test_split(image_files, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[0;32m     46\u001B[0m \u001B[38;5;66;03m# Create DataLoader for training and validation\u001B[39;00m\n\u001B[0;32m     47\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m SegmentationDataset(train_files, label_folder, transform\u001B[38;5;241m=\u001B[39mdata_transform)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    211\u001B[0m         )\n\u001B[0;32m    212\u001B[0m     ):\n\u001B[1;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    223\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2785\u001B[0m, in \u001B[0;36mtrain_test_split\u001B[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001B[0m\n\u001B[0;32m   2782\u001B[0m arrays \u001B[38;5;241m=\u001B[39m indexable(\u001B[38;5;241m*\u001B[39marrays)\n\u001B[0;32m   2784\u001B[0m n_samples \u001B[38;5;241m=\u001B[39m _num_samples(arrays[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m-> 2785\u001B[0m n_train, n_test \u001B[38;5;241m=\u001B[39m _validate_shuffle_split(\n\u001B[0;32m   2786\u001B[0m     n_samples, test_size, train_size, default_test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.25\u001B[39m\n\u001B[0;32m   2787\u001B[0m )\n\u001B[0;32m   2789\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m shuffle \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n\u001B[0;32m   2790\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m stratify \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2415\u001B[0m, in \u001B[0;36m_validate_shuffle_split\u001B[1;34m(n_samples, test_size, train_size, default_test_size)\u001B[0m\n\u001B[0;32m   2412\u001B[0m n_train, n_test \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(n_train), \u001B[38;5;28mint\u001B[39m(n_test)\n\u001B[0;32m   2414\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_train \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m-> 2415\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   2416\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWith n_samples=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m, test_size=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m and train_size=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m, the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2417\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresulting train set will be empty. Adjust any of the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2418\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maforementioned parameters.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(n_samples, test_size, train_size)\n\u001B[0;32m   2419\u001B[0m     )\n\u001B[0;32m   2421\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m n_train, n_test\n",
      "\u001B[1;31mValueError\u001B[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T09:29:18.875323Z",
     "start_time": "2024-10-12T09:29:18.816132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_files = [os.path.join(dp, f) for dp, dn, filenames in os.walk(\"D:/New folder/Inter_Bootcamp/dataset/train\") for f in filenames if f.endswith('_leftImg8bit.jpg')]\n",
    "\n",
    "print(f\"Found {len(image_files)} image files.\")\n"
   ],
   "id": "17aeae1cd63ef8e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7034 image files.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-10-12T09:31:13.215629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import segmentation_models_pytorch as smp\n",
    "import torchmetrics.functional as tmf\n",
    "from torchmetrics import JaccardIndex \n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "n_classes = 40  # Based on your labels\n",
    "\n",
    "# Split the dataset\n",
    "image_files = [os.path.join(dp, f) for dp, dn, filenames in os.walk(\"D:/New folder/Inter_Bootcamp/dataset/train\") for f in filenames if f.endswith('_leftImg8bit.jpg')]\n",
    "if len(image_files) == 0:\n",
    "    raise ValueError(\"No image files found. Check the directory path or file naming convention.\")\n",
    "    \n",
    "train_files, val_files = train_test_split(image_files, test_size=0.2, random_state=42)\n",
    "\n",
    "class CustomCityscapesDataset(Dataset):\n",
    "    def __init__(self, image_files, label_dir, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        img_name = os.path.basename(img_path).replace('_leftImg8bit.jpg', '')\n",
    "        batch_name = os.path.basename(os.path.dirname(img_path))\n",
    "\n",
    "        label_path = os.path.join(self.label_dir, batch_name, f\"{img_name}_gtFine_labelColors.png\")\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = Image.open(label_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            label = self.transform(label)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Dataset transformation\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CustomCityscapesDataset(train_files, \"D:/New folder/Inter_Bootcamp/dataset/train\", transform=data_transform)\n",
    "val_dataset = CustomCityscapesDataset(val_files, \"D:/New folder/Inter_Bootcamp/dataset/train\", transform=data_transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "# Helper function to encode segmented maps\n",
    "def encode_segmap(mask, label_list):\n",
    "    mask = mask.astype(np.uint8)\n",
    "    label_map = np.zeros(mask.shape[:2], dtype=np.int32)\n",
    "    for label in label_list:\n",
    "        r, g, b = label[11]\n",
    "        color_mask = (mask[:, :, 0] == r) & (mask[:, :, 1] == g) & (mask[:, :, 2] == b)\n",
    "        label_map[color_mask] = label[5]\n",
    "    return label_map\n",
    "\n",
    "# Define the labels (You already have this in your code, ensure consistency)\n",
    "labels_list = [\n",
    "    ('road', 0, 7, 0, 0, 0, 'drivable', 0, 0, False, False, (128, 64, 128)),\n",
    "    ('parking', 1, 9, 255, 1, 1, 'drivable', 1, 0, False, False, (250, 170, 160)),\n",
    "    ('drivable fallback', 2, 255, 255, 2, 1, 'drivable', 1, 0, False, False, (81, 0, 81)),\n",
    "    ('sidewalk', 3, 8, 1, 3, 2, 'non-drivable', 2, 1, False, False, (244, 35, 232)),\n",
    "    ('rail track', 4, 10, 255, 3, 3, 'non-drivable', 3, 1, False, False, (230, 150, 140)),\n",
    "    ('non-drivable fallback', 5, 255, 9, 4, 3, 'non-drivable', 3, 1, False, False, (152, 251, 152)),\n",
    "    ('person', 6, 24, 11, 5, 4, 'living-thing', 4, 2, True, False, (220, 20, 60)),\n",
    "    ('animal', 7, 255, 255, 6, 4, 'living-thing', 4, 2, True, True, (246, 198, 145)),\n",
    "    ('rider', 8, 25, 12, 7, 5, 'living-thing', 5, 2, True, False, (255, 0, 0)),\n",
    "    ('motorcycle', 9, 32, 17, 8, 6, '2-wheeler', 6, 3, True, False, (0, 0, 230)),\n",
    "    ('bicycle', 10, 33, 18, 9, 7, '2-wheeler', 6, 3, True, False, (119, 11, 32)),\n",
    "    ('autorickshaw', 11, 255, 255, 10, 8, 'autorickshaw', 7, 3, True, False, (255, 204, 54)),\n",
    "    ('car', 12, 26, 13, 11, 9, 'car', 7, 3, True, False, (0, 0, 142)),\n",
    "    ('truck', 13, 27, 14, 12, 10, 'large-vehicle', 8, 3, True, False, (0, 0, 70)),\n",
    "    ('bus', 14, 28, 15, 13, 11, 'large-vehicle', 8, 3, True, False, (0, 60, 100)),\n",
    "    ('caravan', 15, 29, 255, 14, 12, 'large-vehicle', 8, 3, True, True, (0, 0, 90)),\n",
    "    ('trailer', 16, 30, 255, 15, 12, 'large-vehicle', 8, 3, True, True, (0, 0, 110)),\n",
    "    ('train', 17, 31, 16, 15, 12, 'large-vehicle', 8, 3, True, True, (0, 80, 100)),\n",
    "    ('vehicle fallback', 18, 355, 255, 15, 12, 'large-vehicle', 8, 3, True, False, (136, 143, 153)),\n",
    "    ('curb', 19, 255, 255, 16, 13, 'barrier', 9, 4, False, False, (220, 190, 40)),\n",
    "    ('wall', 20, 12, 3, 17, 14, 'barrier', 9, 4, False, False, (102, 102, 156)),\n",
    "    ('fence', 21, 13, 4, 18, 15, 'barrier', 10, 4, False, False, (190, 153, 153)),\n",
    "    ('guard rail', 22, 14, 255, 19, 16, 'barrier', 10, 4, False, False, (180, 165, 180)),\n",
    "    ('billboard', 23, 255, 255, 20, 17, 'structures', 11, 4, False, False, (174, 64, 67)),\n",
    "    ('traffic sign', 24, 20, 7, 21, 18, 'structures', 11, 4, False, False, (220, 220, 0)),\n",
    "    ('traffic light', 25, 19, 6, 22, 19, 'structures', 11, 4, False, False, (250, 170, 30)),\n",
    "    ('pole', 26, 17, 5, 23, 20, 'structures', 12, 4, False, False, (153, 153, 153)),\n",
    "    ('polegroup', 27, 18, 255, 23, 20, 'structures', 12, 4, False, False, (153, 153, 153)),\n",
    "    ('obs-str-bar-fallback', 28, 255, 255, 24, 21, 'structures', 12, 4, False, False, (169, 187, 214)),\n",
    "    ('building', 29, 11, 2, 25, 22, 'construction', 13, 5, False, False, (70, 70, 70)),\n",
    "    ('bridge', 30, 15, 255, 26, 23, 'construction', 13, 5, False, False, (150, 100, 100)),\n",
    "    ('tunnel', 31, 16, 255, 26, 23, 'construction', 13, 5, False, False, (150, 120, 90)),\n",
    "    ('vegetation', 32, 21, 8, 27, 24, 'vegetation', 14, 5, False, False, (107, 142, 35)),\n",
    "    ('sky', 33, 23, 10, 28, 25, 'sky', 15, 6, False, False, (70, 130, 180)),\n",
    "    ('fallback background', 34, 255, 255, 29, 25, 'object fallback', 15, 6, False, False, (169, 187, 214)),\n",
    "    ('unlabeled', 35, 0, 255, 255, 255, 'void', 255, 255, False, True, (0, 0, 0)),\n",
    "    ('ego vehicle', 36, 1, 255, 255, 255, 'void', 255, 255, False, True, (0, 0, 0)),\n",
    "    ('rectification border', 37, 2, 255, 255, 255, 'void', 255, 255, False, True, (0, 0, 0)),\n",
    "    ('out of roi', 38, 3, 255, 255, 255, 'void', 255, 255, False, True, (0, 0, 0)),\n",
    "    ('license plate', 39, 255, 255, 255, 255, 'vehicle', 255, 255, False, True, (0, 0, 142)),\n",
    "]\n",
    "\n",
    "# Define the segmentation model with lightning\n",
    "class OurModel(LightningModule):\n",
    "    def __init__(self):\n",
    "        super(OurModel, self).__init__()\n",
    "        self.model = smp.Unet(\n",
    "            encoder_name=\"resnet50\", \n",
    "            encoder_weights=\"imagenet\", \n",
    "            in_channels=3, \n",
    "            classes=n_classes\n",
    "        )\n",
    "        self.lr = 1e-3\n",
    "        self.criterion = smp.losses.DiceLoss(mode='multiclass')\n",
    "        self.metric = JaccardIndex(task='multiclass', num_classes=n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        img, seg = batch\n",
    "        \n",
    "        # Move img and seg to the device (GPU) and set the correct data types\n",
    "        img = img.to(self.device).half()  # Convert input images to float16 and move to GPU\n",
    "        seg = seg.permute(0, 2, 3, 1).cpu().numpy()  # BCHW -> BHWC\n",
    "        seg = np.array([encode_segmap(s, labels_list) for s in seg])  # Encode segmentation mask\n",
    "        seg = torch.tensor(seg, dtype=torch.long).to(self.device)  # Convert to tensor and move to GPU\n",
    "        \n",
    "        output = self(img)\n",
    "        loss = self.criterion(output, seg)\n",
    "        iou = self.metric(output, seg)\n",
    "        \n",
    "        self.log('train_loss', loss, on_epoch=True)\n",
    "        self.log('train_iou', iou, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        img, seg = batch\n",
    "        \n",
    "        # Move img and seg to the device (GPU) and set the correct data types\n",
    "        img = img.to(self.device).half()  # Convert input images to float16 and move to GPU\n",
    "        seg = seg.permute(0, 2, 3, 1).cpu().numpy()  # BCHW -> BHWC\n",
    "        seg = np.array([encode_segmap(s, labels_list) for s in seg])  # Encode segmentation mask\n",
    "        seg = torch.tensor(seg, dtype=torch.long).to(self.device)  # Convert to tensor and move to GPU\n",
    "        \n",
    "        output = self(img)\n",
    "        loss = self.criterion(output, seg)\n",
    "        iou = self.metric(output, seg)\n",
    "        \n",
    "        self.log('val_loss', loss, on_epoch=True)\n",
    "        self.log('val_iou', iou, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "# Training setup\n",
    "checkpoint_callback = ModelCheckpoint(monitor='val_loss', save_top_k=1)\n",
    "trainer = Trainer(\n",
    "    max_epochs=25, \n",
    "    accelerator='gpu', \n",
    "    precision=16, \n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.fit(OurModel(), train_loader, val_loader)\n"
   ],
   "id": "26f52c4b53ad32a7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prakh\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\lightning_fabric\\connector.py:562: UserWarning: 16 is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "  rank_zero_warn(\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "C:\\Users\\prakh\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\pytorch_lightning\\plugins\\precision\\amp.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\prakh\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                   | Params\n",
      "-----------------------------------------------------\n",
      "0 | model     | Unet                   | 32.5 M\n",
      "1 | criterion | DiceLoss               | 0     \n",
      "2 | metric    | MulticlassJaccardIndex | 0     \n",
      "-----------------------------------------------------\n",
      "32.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "32.5 M    Total params\n",
      "130.107   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "38378eb4109bd7af"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
